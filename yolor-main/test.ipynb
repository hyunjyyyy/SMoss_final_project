{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5f06bd",
   "metadata": {},
   "source": [
    "## 1. 패키지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5eaa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T04:20:23.480833Z",
     "start_time": "2023-01-16T04:20:20.505654Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.loss import compute_loss\n",
    "from utils.metrics import ap_per_class\n",
    "from utils.plots import plot_images, output_to_target\n",
    "from utils.torch_utils import select_device, time_synchronized\n",
    "\n",
    "from models.models import *\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14497e",
   "metadata": {},
   "source": [
    "## 2. 성능지표 계산 및 로그기록 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292f99e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T09:12:23.392272Z",
     "start_time": "2022-12-27T09:12:23.375290Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_classes(path):\n",
    "    # Loads *.names file at 'path'\n",
    "    with open(path, 'r') as f:\n",
    "        names = f.read().split('\\n')\n",
    "    return list(filter(None, names))  # filter removes empty strings (such as last line)\n",
    "\n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Source: https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "\n",
    "    # Append sentinel values to beginning and end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
    "\n",
    "    # Compute the precision envelope\n",
    "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
    "\n",
    "    # Integrate area under curve\n",
    "    method = 'interp'  # methods: 'continuous', 'interp'\n",
    "    if method == 'interp':\n",
    "        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n",
    "        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate\n",
    "    else:  # 'continuous'\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n",
    "\n",
    "    return ap, mpre, mrec\n",
    "\n",
    "# def write_log(filename, target_class, target_coord, pred_class, pred_coord, conf, ans_iou, c_TP, c_FP, c_P, c_R):\n",
    "def write_log(filename, target_class, target_coord, pred_class, pred_coord, conf, ans_iou):\n",
    "    row = {'FILENAME': filename,\n",
    "           'target_class': target_class,\n",
    "           'target_xywh': target_coord,\n",
    "           'pred_class': pred_class,\n",
    "           'pred_xywh': pred_coord,\n",
    "           'confidence': conf,\n",
    "           'ans_iou': dict_answer[ans_iou],\n",
    "           # 'c_TP' : c_TP,\n",
    "           # 'c_FP' : c_FP,\n",
    "           # 'c_P' : c_P,\n",
    "           # 'c_R' : c_R\n",
    "           }\n",
    "    return row\n",
    "\n",
    "\n",
    "def get_p_r_data(df, cls, n_target):\n",
    "    df = df.loc[df['pred_class'] == cls]\n",
    "    n_tp = np.repeat(0, len(df))\n",
    "    n_fp = np.repeat(0, len(df))\n",
    "    c_p = np.repeat(0, len(df))\n",
    "    c_r = np.repeat(0, len(df))\n",
    "\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ans_iou'] == 'TP':\n",
    "            n_tp[i:] += 1\n",
    "        if row['ans_iou'] == 'FP':\n",
    "            n_fp[i:] += 1\n",
    "        # if not np.isnan(row['target_class']):\n",
    "        #   n_target[i:] += 1\n",
    "        i += 1\n",
    "\n",
    "    c_p = n_tp / (n_tp + n_fp)\n",
    "    c_r = n_tp / n_target\n",
    "\n",
    "    return n_tp, n_fp, c_p, c_r\n",
    "\n",
    "dict_answer = {0: 'TP', 1: 'FN', 2: 'FP'}  # 'TN' does not exists for object detection.\n",
    "const_TP = 0\n",
    "const_FN = 1\n",
    "const_FP = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01ce7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T09:13:01.948582Z",
     "start_time": "2022-12-27T09:13:01.939585Z"
    }
   },
   "source": [
    "## 3. 환경설정 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aee34d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T04:22:47.268079Z",
     "start_time": "2023-01-16T04:22:47.249506Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = argparse.Namespace(\n",
    "    weights = ['runs/train/newconn_model/weights/last.pt'],\n",
    "    data = 'data/newconn.yaml',\n",
    "    batch_size = 16,\n",
    "    img_size = 640,\n",
    "    conf_thres=0.01,\n",
    "    iou_thres=0.5,  # for NMS\n",
    "    task='test',\n",
    "    device = '',\n",
    "    single_cls=False,\n",
    "    augment=False,\n",
    "    verbose=True,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    save_json=False,\n",
    "    save_ans_log=False,\n",
    "    project='runs/test',\n",
    "    name='newconn_test',\n",
    "    exist_ok=False,\n",
    "    cfg='cfg/yolor_p6.cfg',\n",
    "    names='data/newconn.names'\n",
    ")\n",
    "\n",
    "data = opt.data\n",
    "weights = opt.weights\n",
    "if opt.save_ans_log:\n",
    "    batch_size = 1\n",
    "else:\n",
    "    batch_size = opt.batch_size\n",
    "imgsz = opt.img_size\n",
    "conf_thres = opt.conf_thres\n",
    "iou_thres = opt.iou_thres\n",
    "save_json = opt.save_json\n",
    "save_ans_log = opt.save_ans_log\n",
    "single_cls = opt.single_cls\n",
    "augment = opt.augment\n",
    "verbose = opt.verbose\n",
    "model = None\n",
    "dataloader = None\n",
    "save_dir = Path(''),  # for saving images\n",
    "save_txt = opt.save_txt,  # for auto-labelling\n",
    "save_conf = opt.save_conf,\n",
    "plots = True,\n",
    "log_imgs = 0  # number of logged images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbd542",
   "metadata": {},
   "source": [
    "## 4. 테스트 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc31c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T09:17:41.105071Z",
     "start_time": "2022-12-27T09:17:41.036075Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(data,\n",
    "         weights=None,\n",
    "         batch_size=16,\n",
    "         imgsz=640,\n",
    "         conf_thres=0.001,\n",
    "         iou_thres=0.6,  # for NMS\n",
    "         save_json=False,\n",
    "         save_ans_log=False,\n",
    "         single_cls=False,\n",
    "         augment=False,\n",
    "         verbose=False,\n",
    "         model=None,\n",
    "         dataloader=None,\n",
    "         save_dir=Path(''),  # for saving images\n",
    "         save_txt=False,  # for auto-labelling\n",
    "         save_conf=False,\n",
    "         plots=True,\n",
    "         log_imgs=0):  # number of logged images\n",
    "\n",
    "    # Initialize/load model and set device\n",
    "    training = model is not None\n",
    "    if training:  # called by train.py\n",
    "        device = next(model.parameters()).device  # get model device\n",
    "\n",
    "    else:  # called directly\n",
    "        set_logging()\n",
    "        device = select_device(opt.device, batch_size=batch_size)\n",
    "        save_txt = opt.save_txt  # save *.txt labels\n",
    "\n",
    "        # Directories\n",
    "        save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
    "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "        # Load model\n",
    "        model = Darknet(opt.cfg).to(device)\n",
    "\n",
    "        # load model\n",
    "        try:\n",
    "            ckpt = torch.load(weights[0], map_location=device)  # load checkpoint\n",
    "            ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "            model.load_state_dict(ckpt['model'], strict=False)\n",
    "        except:\n",
    "            load_darknet_weights(model, weights[0])\n",
    "        imgsz = check_img_size(imgsz, s=64)  # check img_size\n",
    "\n",
    "    # Half\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "    if half:\n",
    "        model.half()\n",
    "\n",
    "    # Configure\n",
    "    model.eval()\n",
    "    is_coco = data.endswith('coco.yaml')  # is COCO dataset\n",
    "    with open(data) as f:\n",
    "        data = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
    "    check_dataset(data)  # check\n",
    "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "    niou = iouv.numel()\n",
    "\n",
    "    # Logging\n",
    "    log_imgs, wandb = min(log_imgs, 100), None  # ceil\n",
    "    try:\n",
    "        import wandb  # Weights & Biases\n",
    "    except ImportError:\n",
    "        log_imgs = 0\n",
    "\n",
    "    # Dataloader\n",
    "    if not training:\n",
    "        img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "        _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "        path = data['test'] if opt.task == 'test' else data['val']  # path to val/test images\n",
    "        dataloader = create_dataloader(path, imgsz, batch_size, 64, opt, pad=0.5, rect=True)[0]\n",
    "\n",
    "    seen = 0\n",
    "    try:\n",
    "        names = model.names if hasattr(model, 'names') else model.module.names\n",
    "    except:\n",
    "        names = load_classes(opt.names)\n",
    "    coco91class = coco80_to_coco91_class()\n",
    "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Targets', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
    "    loss = torch.zeros(3, device=device)\n",
    "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
    "\n",
    "    # 새로 추가된 초기값\n",
    "    list_row = []\n",
    "\n",
    "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        targets = targets.to(device)\n",
    "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "        whwh = torch.Tensor([width, height, width, height]).to(device)\n",
    "\n",
    "        # Disable gradients\n",
    "        with torch.no_grad():\n",
    "            # Run model\n",
    "            t = time_synchronized()\n",
    "            inf_out, train_out = model(img, augment=augment)  # inference and training outputs\n",
    "            t0 += time_synchronized() - t\n",
    "\n",
    "            # Compute loss\n",
    "            if training:  # if model has loss hyperparameters\n",
    "                loss += compute_loss([x.float() for x in train_out], targets, model)[1][:3]  # box, obj, cls\n",
    "\n",
    "            # Run NMS\n",
    "            t = time_synchronized()\n",
    "            output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "            t1 += time_synchronized() - t\n",
    "\n",
    "        # Statistics per image\n",
    "        for si, pred in enumerate(output):\n",
    "            labels = targets[targets[:, 0] == si, 1:]\n",
    "            nl = len(labels)\n",
    "\n",
    "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "            seen += 1\n",
    "\n",
    "            if len(pred) == 0:\n",
    "                if nl:  # if tbox has no matching pbox (FN)\n",
    "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "\n",
    "                    # get tbox_pbox logs\n",
    "                    if save_ans_log:\n",
    "                        gn = np.tile(shapes[si][0][::-1], 2)\n",
    "                        tbox_original = xywh2xyxy(labels.clone()[:, 1:5]) * whwh\n",
    "                        tbox_original = scale_coords(img[si].shape[1:], tbox_original, shapes[si][0], shapes[si][1])\n",
    "                        tbox_original = (xyxy2xywh(tbox_original) / gn).tolist()\n",
    "                        tbox_class = tcls\n",
    "\n",
    "                        # write log by imagefile - target box\n",
    "                        for k in range(0, nl):\n",
    "                            row = write_log(paths[0], tbox_class[k], tbox_original[k], np.nan, np.nan, np.nan, const_FN)\n",
    "\n",
    "                            list_row.append(pd.DataFrame([row]))\n",
    "\n",
    "                continue\n",
    "\n",
    "            # Append to text file\n",
    "            path = Path(paths[si])\n",
    "            if save_txt:\n",
    "                gn = torch.tensor(shapes[si][0])[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "                x = pred.clone()\n",
    "                x[:, :4] = scale_coords(img[si].shape[1:], x[:, :4], shapes[si][0], shapes[si][1])  # to original\n",
    "                for *xyxy, conf, cls in x:\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "                    with open(save_dir / 'labels' / (path.stem + '.txt'), 'a') as f:\n",
    "                        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "            # W&B logging\n",
    "            if plots and len(wandb_images) < log_imgs:\n",
    "                box_data = [{\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
    "                             \"class_id\": int(cls),\n",
    "                             \"box_caption\": \"%s %.3f\" % (names[cls], conf),\n",
    "                             \"scores\": {\"class_score\": conf},\n",
    "                             \"domain\": \"pixel\"} for *xyxy, conf, cls in pred.tolist()]\n",
    "                boxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}\n",
    "                wandb_images.append(wandb.Image(img[si], boxes=boxes, caption=path.name))\n",
    "\n",
    "            # Clip boxes to image bounds\n",
    "            clip_coords(pred, (height, width))\n",
    "\n",
    "            # pbox matched tbox index\n",
    "            list_pbox_matched_tbox = [-1 for i in range(len(pred))]\n",
    "\n",
    "            # Assign all predictions as incorrect\n",
    "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
    "            if nl:\n",
    "                detected = []  # target indices\n",
    "                tcls_tensor = labels[:, 0]\n",
    "\n",
    "                # target boxes\n",
    "                tbox = xywh2xyxy(labels[:, 1:5]) * whwh\n",
    "\n",
    "                # Per target class\n",
    "                for cls in torch.unique(tcls_tensor):\n",
    "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
    "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
    "\n",
    "                    if pi.shape[0]:\n",
    "                        # Prediction to target ious\n",
    "                        ious, i = box_iou(pred[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
    "\n",
    "                        # Append detections\n",
    "                        detected_set = set()\n",
    "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
    "                            d = ti[i[j]]  # detected target\n",
    "                            if d.item() not in detected_set:\n",
    "                                detected_set.add(d.item())\n",
    "                                detected.append(d.item())\n",
    "\n",
    "                                list_pbox_matched_tbox[pi[j]] = d\n",
    "\n",
    "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
    "                                if len(detected) == nl:  # all targets already located in image\n",
    "                                    break\n",
    "\n",
    "            # Append statistics (correct, conf, pcls, tcls)\n",
    "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
    "\n",
    "            # get tbox_pbox logs\n",
    "            if save_ans_log:\n",
    "                gn = np.tile(shapes[si][0][::-1], 2)\n",
    "                tbox_original = tbox.clone()[:, :4]\n",
    "                tbox_original = scale_coords(img[si].shape[1:], tbox_original, shapes[si][0], shapes[si][1])\n",
    "                tbox_original = (xyxy2xywh(tbox_original) / gn).tolist()\n",
    "                tbox_class = tcls\n",
    "\n",
    "                pbox_original = pred.clone()\n",
    "                pbox_original = scale_coords(img[si].shape[1:], pbox_original[:, :4], shapes[si][0], shapes[si][1])\n",
    "                pbox_original = (xyxy2xywh(pbox_original) / gn).tolist()\n",
    "                pbox_class = pred[:, 5].tolist()\n",
    "                pbox_conf = pred[:, 4].tolist()\n",
    "\n",
    "                list_correct_iou50 = correct[:, 0].tolist()\n",
    "\n",
    "                # write log by imagefile - target box\n",
    "                for k in range(0, nl):\n",
    "\n",
    "                    # if k in detected:  # if tbox has a matching pbox at IOU : 0.5 (TP)\n",
    "                    if k in list_pbox_matched_tbox:  # if tbox has a matching pbox at IOU : 0.5 (TP)\n",
    "                        pbox_index = list_pbox_matched_tbox.index(k)\n",
    "\n",
    "                        if list_correct_iou50[pbox_index] == True:\n",
    "                            row = write_log(paths[0], tbox_class[k], tbox_original[k],\n",
    "                                            pbox_class[pbox_index], pbox_original[pbox_index],\n",
    "                                            pbox_conf[pbox_index],\n",
    "                                            const_TP)\n",
    "                        else:  # if pbox has not enough iou (FP)\n",
    "                            row = write_log(paths[0], tbox_class[k], tbox_original[k],\n",
    "                                            pbox_class[pbox_index], pbox_original[pbox_index],\n",
    "                                            pbox_conf[pbox_index],\n",
    "                                            const_FP)\n",
    "                    else:  # if tbox has no matching pbox (FN)\n",
    "                        row = write_log(paths[0], tbox_class[k], tbox_original[k], np.nan, np.nan, np.nan, const_FN)\n",
    "\n",
    "                    list_row.append(pd.DataFrame([row]))\n",
    "\n",
    "                # if pbox has not matching tbox (FP)\n",
    "                for pbox_index in [i for i, v in enumerate(list_pbox_matched_tbox) if v == -1]:\n",
    "                    row = write_log(paths[0], np.nan, np.nan,\n",
    "                                    pbox_class[pbox_index], pbox_original[pbox_index], pbox_conf[pbox_index],\n",
    "                                    const_FP)\n",
    "                    list_row.append(pd.DataFrame([row]))\n",
    "\n",
    "\n",
    "\n",
    "        # Plot images\n",
    "        if plots and batch_i < 3:\n",
    "            f = save_dir / f'test_batch{batch_i}_labels.jpg'  # filename\n",
    "            plot_images(img, targets, paths, f, names)  # labels\n",
    "            f = save_dir / f'test_batch{batch_i}_pred.jpg'\n",
    "            plot_images(img, output_to_target(output, width, height), paths, f, names)  # predictions\n",
    "            #plot_images(img, output_to_target(output.cpu().numpy(), width, height), paths, f, names)  # predictions\n",
    "\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
    "    if len(stats) and stats[0].any():\n",
    "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, fname=save_dir / 'precision-recall_curve.png')\n",
    "        p, r, ap50, ap = p[:, 0], r[:, 0], ap[:, 0], ap.mean(1)  # [P, R, AP@0.5, AP@0.5:0.95]\n",
    "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
    "    else:\n",
    "        nt = torch.zeros(1)\n",
    "\n",
    "    # W&B logging\n",
    "    if plots and wandb:\n",
    "        wandb.log({\"Images\": wandb_images})\n",
    "        wandb.log({\"Validation\": [wandb.Image(str(x), caption=x.name) for x in sorted(save_dir.glob('test*.jpg'))]})\n",
    "\n",
    "    # Print results\n",
    "    pf = '%20s' + '%12.3g' * 6  # print format\n",
    "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "\n",
    "    # Print results per class\n",
    "    if verbose and nc > 1 and len(stats):\n",
    "        for i, c in enumerate(ap_class):\n",
    "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
    "\n",
    "    # Print speeds\n",
    "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
    "    if not training:\n",
    "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
    "\n",
    "\n",
    "    # Return results\n",
    "    if not training:\n",
    "        print('Results saved to %s' % save_dir)\n",
    "    model.float()  # for training\n",
    "    maps = np.zeros(nc) + map\n",
    "    for i, c in enumerate(ap_class):\n",
    "        maps[c] = ap[i]\n",
    "\n",
    "    if save_ans_log:\n",
    "        df = pd.concat(list_row)\n",
    "        df['target_xywh'] = df.apply(lambda x: np.round(x['target_xywh'], 5), axis=1)\n",
    "        df['pred_xywh'] = df.apply(lambda x: np.round(x['pred_xywh'], 5), axis=1)\n",
    "        df['FILENAME'] = df['FILENAME'].str.extract(r'([^\\\\]+$)')\n",
    "\n",
    "        n_target_by_cls = df['target_class'].value_counts().sort_index()\n",
    "\n",
    "        list_df = []\n",
    "        list_ap = []\n",
    "        for i, cls in enumerate(n_target_by_cls.index):\n",
    "            df_tmp = df.loc[df['pred_class'] == cls]\n",
    "            df_tmp = df_tmp.sort_values('confidence', ascending=False)\n",
    "\n",
    "            n_tp, n_fp, c_p, c_r = get_p_r_data(df_tmp, cls, n_target_by_cls[cls])\n",
    "\n",
    "            df_tmp['n_tp'] = n_tp\n",
    "            df_tmp['n_fp'] = n_fp\n",
    "            df_tmp['c_p'] = c_p\n",
    "            df_tmp['c_r'] = c_r\n",
    "\n",
    "            # calculate ap50\n",
    "            ap, mpre, mrec = compute_ap(c_r, c_p)\n",
    "            print('class :  {0} > target : {1}  /  AP@0.5 : {2:.5f}'.format(i, n_target_by_cls[cls], ap))\n",
    "            list_ap.append(ap)\n",
    "            list_df.append(df_tmp)\n",
    "\n",
    "            # plot p-r curve\n",
    "            px, py = np.linspace(0, 1, 1000), []  # for plotting\n",
    "            py.append(np.interp(px, mrec, mpre))\n",
    "\n",
    "            fname = 'precision-recall_curve_class_{0}.png'.format(i)\n",
    "\n",
    "            # py = np.stack(py, axis=1)\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            ax.plot(px, py[0], linewidth=0.5, color='grey')  # plot(recall, precision)\n",
    "            ax.plot(px, py[0], linewidth=2, color='blue', label='class {0} AP@0.5 {1:.4f}'.format(i, ap))\n",
    "            ax.set_xlabel('Recall')\n",
    "            ax.set_ylabel('Precision')\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_ylim(0, 1)\n",
    "            plt.legend()\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(save_dir / fname, dpi=200)\n",
    "\n",
    "        print('class :  all > target : {0}  /  AP@0.5 : {1:.5f}'.format(np.sum(n_target_by_cls), np.mean(list_ap)))\n",
    "        df_export = pd.concat(list_df)\n",
    "        df_export.to_csv(save_dir / 'test_log.csv', index=False)\n",
    "\n",
    "\n",
    "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c253c88",
   "metadata": {},
   "source": [
    "## 5. 테스트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507962e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-27T09:18:34.025417Z",
     "start_time": "2022-12-27T09:17:42.360555Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "opt.data = check_file(opt.data)  # check file\n",
    "print(opt)\n",
    "\n",
    "if opt.task in ['val', 'test']:  # run normally\n",
    "\n",
    "    now = datetime.now()\n",
    "    print(\"Model Test Start at \", now)\n",
    "    print('\\n')\n",
    "\n",
    "    test(opt.data,\n",
    "         opt.weights,\n",
    "         opt.batch_size,\n",
    "         opt.img_size,\n",
    "         opt.conf_thres,\n",
    "         opt.iou_thres,\n",
    "         opt.save_json,\n",
    "         opt.save_ans_log,\n",
    "         opt.single_cls,\n",
    "         opt.augment,\n",
    "         opt.verbose,\n",
    "         save_txt=opt.save_txt,\n",
    "         save_conf=opt.save_conf,\n",
    "         )\n",
    "\n",
    "    now = datetime.now()\n",
    "    print('\\n')\n",
    "    print(\"Model Test End at \", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ae25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b548174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
